# -*- coding: utf-8 -*-
import re
from dotenv import load_dotenv

# æ–°ç‰ˆ LangChain ç»„ä»¶ï¼ˆæ›¿ä»£ LLMChainï¼‰
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI

load_dotenv()  # è¯»å– .env é‡Œçš„ OPENAI_API_KEY ä¸ OPENAI_API_BASEï¼ˆæˆ– base_urlï¼‰

# ============ 0) åˆå§‹åŒ– DeepSeekï¼ˆChat æ¨¡å‹ï¼‰ ============
# è¯´æ˜ï¼šChatOpenAI åŒæ—¶å…¼å®¹ DeepSeekï¼ˆOpenAI åè®®ï¼‰ã€‚å¯ç”¨ç¯å¢ƒå˜é‡æˆ–ä»£ç ä¼  base_urlã€‚
llm = ChatOpenAI(
    model="deepseek-chat",
    temperature=0.7,
    # å¦‚æœä½ æ²¡åœ¨ .env é‡Œé… OPENAI_API_BASEï¼Œå¯å–æ¶ˆä¸‹ä¸€è¡Œæ³¨é‡Šæ‰‹åŠ¨æŒ‡å®šï¼š
    # base_url="https://api.deepseek.com/v1"
)

# ç»Ÿä¸€çš„é€šç”¨å›ç­”é“¾ï¼šprompt â†’ llm â†’ çº¯æ–‡æœ¬
prompt = ChatPromptTemplate.from_template("è¯·ç”¨ç®€æ´ä¸­æ–‡å›ç­”ï¼š{question}")
default_chain = prompt | llm | StrOutputParser()

# ============ 1) æ„å›¾è¯†åˆ«ï¼ˆè§„åˆ™ç‰ˆ Planner é›å½¢ï¼‰ ============
def detect_intent(user_input: str) -> str:
    # è¡¥å……äº†â€œå“ªä¸ªå¥½/å¯¹æ¯”/æ¯”è¾ƒ/å“ªä¸ªæ›´â€¦â€ç­‰å…³é”®è¯
    if re.search(r"(å¥½ä¸å¥½|ä¼˜ç¼ºç‚¹|å€¼å¾—ä¹°å—|è¯„ä»·|å“ªä¸ªå¥½|å¯¹æ¯”|æ¯”è¾ƒ|å“ªä¸ªæ›´)", user_input):
        return "analysis"
    elif re.search(r"(æ˜¯ä»€ä¹ˆ|å®šä¹‰|ä»‹ç»|åŠŸèƒ½)", user_input):
        return "fact"
    else:
        return "default"

# ============ 2) å·¥å…·å‡½æ•°ï¼ˆæ¨¡æ‹Ÿå·¥å…·ç®±ï¼‰ ============
def search_knowledge(query: str):
    docs = {
        "ç™¾å²å±±": "ç™¾å²å±±æ˜¯å¤©ç„¶çŸ¿æ³‰æ°´å“ç‰Œï¼Œå¼ºè°ƒâ€œå¤©ç„¶å¥½æ°´â€çš„å“ç‰Œç†å¿µã€‚",
        "å†œå¤«å±±æ³‰": "å†œå¤«å±±æ³‰ä»¥â€œæˆ‘ä»¬ä¸ç”Ÿäº§æ°´ï¼Œæˆ‘ä»¬åªæ˜¯å¤§è‡ªç„¶çš„æ¬è¿å·¥â€ä¸ºæ ¸å¿ƒå£å·ã€‚"
    }
    return docs.get(query, "æœªæ‰¾åˆ°ç›¸å…³èµ„æ–™ã€‚")

def compare_products(p1, p2):
    return f"{p1}åœ¨å“ç‰Œç†å¿µä¸Šæ›´å¼ºè°ƒè‡ªç„¶çº¯å‡€ï¼Œè€Œ{p2}æ³¨é‡å¸‚åœºä¼ æ’­ä¸ç”¨æˆ·è§¦è¾¾ã€‚"

# ============ 3) ä¸»æ§åˆ¶é€»è¾‘ï¼ˆExecutorï¼‰ ============
def agent_response(user_input: str):
    intent = detect_intent(user_input)
    print(f"âœ… è¯†åˆ«æ„å›¾ï¼š{intent}")

    if intent == "fact":
        # å–å‡ºå…³é”®è¯ï¼šæŠŠâ€œæ˜¯ä»€ä¹ˆâ€å»æ‰ï¼Œå¾—åˆ°æŸ¥è¯¢è¯
        product = user_input.replace("æ˜¯ä»€ä¹ˆ", "").strip()
        info = search_knowledge(product)
        return f"{product}çš„ç®€ä»‹å¦‚ä¸‹ï¼š{info}"

    elif intent == "analysis":
        # æå–å‡ºç°çš„å“ç‰Œå
        products = re.findall(r"(ç™¾å²å±±|å†œå¤«å±±æ³‰|æ€¡å®)", user_input)
        products = list(dict.fromkeys(products))  # å»é‡ï¼Œé˜²æ­¢é‡å¤åŒ¹é…

        if len(products) >= 2:
            return compare_products(products[0], products[1])
        elif len(products) == 1:
            return f"å…³äº{products[0]}çš„æ€»ä½“è¯„ä»·ï¼šå£æ„Ÿçº¯å‡€ï¼Œå®šä½è¾ƒé«˜ç«¯ã€‚"
        else:
            # æ²¡æŠ“åˆ°å“ç‰Œåï¼Œå°±èµ°é»˜è®¤é“¾è¯· LLM å…ˆç»™å‡ºåˆ†ææ€è·¯
            return default_chain.invoke({"question": f"ç”¨æˆ·è¦å¯¹æ¯”è¯„ä»·è¿™ç±»é¥®ç”¨æ°´å“ç‰Œï¼š{user_input}ï¼Œè¯·å…ˆæå‡ºè¯„ä»·ç»´åº¦ã€‚"})

    else:
        # æ–°å†™æ³•ï¼šä½¿ç”¨ Runnable çš„ invokeï¼Œè€Œä¸æ˜¯ LLMChain.run
        return default_chain.invoke({"question": user_input})

# ============ 4) æœ¬åœ°äº¤äº’æµ‹è¯• ============
if __name__ == "__main__":
    # é¢„ç½®ä¸‰æ¡
    print(agent_response("ç™¾å²å±±æ˜¯ä»€ä¹ˆ"))
    print(agent_response("ç™¾å²å±±å’Œå†œå¤«å±±æ³‰å“ªä¸ªå¥½ï¼Ÿ"))
    print(agent_response("ä½ å–œæ¬¢ä»€ä¹ˆæ°´ï¼Ÿ"))

    # å¯é€‰ï¼šäº¤äº’æ¨¡å¼
    # while True:
    #     q = input("ğŸ’¬ è¯·è¾“å…¥ï¼ˆexité€€å‡ºï¼‰ï¼š")
    #     if q.lower() == "exit":
    #         break
    #     print(agent_response(q))
